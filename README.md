# ğŸ¬ Multilingual Movie Reviews NLP Pipeline

This project builds an end-to-end **Natural Language Processing (NLP) pipeline** to analyze movie reviews in **English** and **Spanish**, performing:
- Text Cleaning & Tokenization  
- POS Tagging & Parsing  
- Named Entity Recognition (NER)  
- Sentiment Analysis (Positive/Negative Classification)

The project is modular, fully reproducible, and runs on a small sampled dataset (20K reviews total).

---

## ğŸ§  Project Overview

| Component | Description |
|------------|--------------|
| **Languages** | English ğŸ‡¬ğŸ‡§ & Spanish ğŸ‡ªğŸ‡¸ |
| **Dataset** | 10K English + 10K Spanish movie reviews (balanced positive/negative) |
| **Goal** | Implement end-to-end NLP pipeline, Detect sentiment and extract named entities |
| **Libraries Used** | `pandas`, `spaCy`, `nltk`, `scikit-learn`, `matplotlib`, `seaborn`, `tqdm`, `contractions`, `math`, `re`, `ngrams`, `displacy`, `counter` |
| **Pipeline Entry** | `run_pipeline.py` |
| **Environment** | Python Virtual Environment (`.venv`) |

---

## ğŸ§© Folder Structure

```
â”œâ”€â”€ .venv/
â”œâ”€â”€ data/
â”‚Â Â  â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ 01_cleaned_imdb_en.csv
â”‚   â”‚   â”œâ”€â”€ 01_cleaned_imdb_es.csv
â”‚   â”‚   â”œâ”€â”€ 02_tokenized_pos_imdb_en.csv
â”‚   â”‚   â””â”€â”€ 02_tokenized_pos_imdb_es.csv
â”‚Â Â  â””â”€â”€ raw/
â”‚Â Â      â”œâ”€â”€ MUSTREAD.txt
â”‚Â Â      â”œâ”€â”€ sampled_imdb_en.csv
â”‚Â Â      â””â”€â”€ sampled_imdb_es.csv
â”œâ”€â”€ notebooks/
â”‚Â Â  â”œâ”€â”€ 01_data_cleaning_eda.ipynb
â”‚Â Â  â”œâ”€â”€ 02_tokenization_ngram_pos.ipynb
â”‚Â Â  â”œâ”€â”€ sampleChecker.ipynb
â”‚Â Â  â”œâ”€â”€ sampleGenerator_en.ipynb
â”‚Â Â  â””â”€â”€ sampleGenerator_es.ipynb
â”œâ”€â”€ outputs/
â”‚Â Â  â”œâ”€â”€ TEST_cleaned_imdb_en.csv
â”‚Â Â  â”œâ”€â”€ TEST_cleaned_imdb_es.csv
â”‚Â Â  â”œâ”€â”€ TEST_tokenized_pos_en.csv
â”‚Â Â  â””â”€â”€ TEST_tokenized_pos_es.csv
â”œâ”€â”€ src/
â”‚Â Â  â”œâ”€â”€ dependency.html
â”‚Â Â  â””â”€â”€ nlp_utils.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ run_pipeline.py
```
---

## ğŸ“š Dataset Information

The original datasets are sourced from **Kaggle** and have been legally sampled for academic use:

1. **English Dataset:**  
   *IMDB Dataset of 50K Movie Reviews* â€” includes labeled positive and negative reviews.  
   ğŸ”— https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/data

2. **Spanish Dataset:**  
   *IMDB Dataset of 50K Movie Reviews (Spanish Translation)* â€” machine-translated and labeled for sentiment.  
   ğŸ”— https://www.kaggle.com/datasets/luisdiegofv97/imdb-dataset-of-50k-movie-reviews-spanish/data

Each dataset was reduced to **10,000 randomly sampled reviews per language** to ensure balanced sentiment distribution and faster model training.


## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Meshal6299/multilingual-movie-reviews-NLP.git

cd multilingual-movie-reviews-NLP
```

### 2ï¸âƒ£ Create and Activate a Virtual Environment
```bash
python -m venv .venv

# ğŸªŸ Windows
.venv\Scripts\activate
# ğŸ§ macOS / Linux
source .venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Download spaCy Models
```bash
python -m spacy download en_core_web_sm
python -m spacy download es_core_news_sm
```

### 5ï¸âƒ£ Run the Full NLP Pipeline  
```bash
python run_pipeline.py
```

**This will automatically:**
1. Clean and normalize raw data 
2. Tokenize English & Spanish reviews
3. Build N-gram models and calculate perplexity
4. Apply POS tagging

All outputs are saved under `outputs/`.
