{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meshal6299/multilingual-movie-reviews-NLP/blob/main/notebooks/03_sentiment_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eCtjenmS3-PN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import pickle\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evO6pBKo4cF0",
        "outputId": "1cc0bb0e-c03c-4f7b-8cec-b522b7d25a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O8hFEZ4Q4MG1"
      },
      "outputs": [],
      "source": [
        "# Load spaCy models\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_es = spacy.load(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNEBFKwJ4vQV",
        "outputId": "5dc1e008-4893-4fb4-b7da-d066776ed885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets loaded successfully!\n",
            "                                          clean_text sentiment\n",
            "0  starts really well nice intro and build up for...  negative\n",
            "1  terrific movie if you did not watch yet you mu...  positive\n",
            "2  i have seen hundreds of silent movies some wil...  positive\n",
            "3  i had been looking for this film for so long b...  positive\n",
            "4  good engaging cinematic firefights great prese...  positive \n",
            "\n",
            "                                          clean_text sentiment\n",
            "0  comienza muy bien bonita intro y acumule para ...  negativo\n",
            "1  película excelente si aún no lo observaste deb...  positivo\n",
            "2  he visto cientos de películas silenciosas algu...  positivo\n",
            "3  había estado buscando esta película durante ta...  positivo\n",
            "4  bueno atractiva firefights cinematicales una g...  positivo\n"
          ]
        }
      ],
      "source": [
        "# Load the cleaned datasets\n",
        "eng = pd.read_csv(\"../data/processed/01_cleaned_imdb_en.csv\")\n",
        "spa = pd.read_csv(\"../data/processed/01_cleaned_imdb_es.csv\")\n",
        "\n",
        "print(\"Datasets loaded successfully!\")\n",
        "print(eng.head(), \"\\n\")\n",
        "print(spa.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alVDvarJ5W5d",
        "outputId": "fc174e7e-362c-4314-f487-7f37fec427b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF vectors created!\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit English vectorizer on English only\n",
        "X_en = vectorizer.fit_transform(eng[\"clean_text\"])\n",
        "y_en = eng[\"sentiment\"]\n",
        "\n",
        "# Fit new Spanish vectorizer on Spanish only\n",
        "vectorizer_es = TfidfVectorizer(max_features=5000)\n",
        "X_es = vectorizer_es.fit_transform(spa[\"clean_text\"])\n",
        "y_es = spa[\"sentiment\"]\n",
        "\n",
        "print(\"TF-IDF vectors created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsMJEZVF5hRw",
        "outputId": "9ccfc66c-27ac-4cfd-d3d7-ffbbaecda000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment models trained!\n"
          ]
        }
      ],
      "source": [
        "X_train_en, X_test_en, y_train_en, y_test_en = train_test_split(\n",
        "    X_en, y_en, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train_es, X_test_es, y_train_es, y_test_es = train_test_split(\n",
        "    X_es, y_es, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model_en = LogisticRegression(max_iter=2000)\n",
        "model_es = LogisticRegression(max_iter=2000)\n",
        "\n",
        "model_en.fit(X_train_en, y_train_en)\n",
        "model_es.fit(X_train_es, y_train_es)\n",
        "\n",
        "print(\"Sentiment models trained!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "sKUcPcBJ5nxw",
        "outputId": "2bcf61be-9bef-47da-8663-d0080d673a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ENGLISH SENTIMENT CLASSIFICATION ===\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.86      0.86       987\n",
            "    positive       0.86      0.87      0.87      1013\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.86      0.86      0.86      2000\n",
            "weighted avg       0.86      0.86      0.86      2000\n",
            "\n",
            "\n",
            "=== SPANISH SENTIMENT CLASSIFICATION ===\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.85      0.85      0.85       987\n",
            "    positivo       0.85      0.86      0.85      1013\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>English</td>\n",
              "      <td>0.8645</td>\n",
              "      <td>0.864483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Spanish</td>\n",
              "      <td>0.8520</td>\n",
              "      <td>0.851993</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Language  Accuracy  F1-score\n",
              "0  English    0.8645  0.864483\n",
              "1  Spanish    0.8520  0.851993"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_en = model_en.predict(X_test_en)\n",
        "pred_es = model_es.predict(X_test_es)\n",
        "\n",
        "print(\"\\n=== ENGLISH SENTIMENT CLASSIFICATION ===\\n\")\n",
        "print(classification_report(y_test_en, pred_en))\n",
        "\n",
        "print(\"\\n=== SPANISH SENTIMENT CLASSIFICATION ===\\n\")\n",
        "print(classification_report(y_test_es, pred_es))\n",
        "\n",
        "# Store summarized numbers\n",
        "results = pd.DataFrame({\n",
        "    \"Language\": [\"English\", \"Spanish\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test_en, pred_en),\n",
        "        accuracy_score(y_test_es, pred_es)\n",
        "    ],\n",
        "    \"F1-score\": [\n",
        "        f1_score(y_test_en, pred_en, average=\"weighted\"),\n",
        "        f1_score(y_test_es, pred_es, average=\"weighted\")\n",
        "    ]\n",
        "})\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W_yIYSm6u0H",
        "outputId": "18f3a313-b03a-4dc3-ace2-cc9bb58d031c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models saved!\n"
          ]
        }
      ],
      "source": [
        "pickle.dump(model_en, open(\"../src/sentiment_en.pkl\", \"wb\"))\n",
        "pickle.dump(model_es, open(\"../src/sentiment_es.pkl\", \"wb\"))\n",
        "\n",
        "pickle.dump(vectorizer, open(\"../src/vectorizer_en.pkl\", \"wb\"))\n",
        "pickle.dump(vectorizer_es, open(\"../src/vectorizer_es.pkl\", \"wb\"))\n",
        "\n",
        "print(\"Models saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "CmtbCjIC7KEC",
        "outputId": "bc227851-9043-417c-da19-99812cdda64b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NER extraction complete!\n"
          ]
        }
      ],
      "source": [
        "def extract_ner(doc):\n",
        "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "eng[\"entities\"] = eng[\"clean_text\"].apply(lambda x: extract_ner(nlp_en(x)))\n",
        "spa[\"entities\"] = spa[\"clean_text\"].apply(lambda x: extract_ner(nlp_es(x)))\n",
        "\n",
        "print(\"NER extraction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5odUVaM1B734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          clean_text  \\\n",
            "0  starts really well nice intro and build up for...   \n",
            "1  terrific movie if you did not watch yet you mu...   \n",
            "2  i have seen hundreds of silent movies some wil...   \n",
            "3  i had been looking for this film for so long b...   \n",
            "4  good engaging cinematic firefights great prese...   \n",
            "\n",
            "                                            entities  \n",
            "0  [(about minutes, TIME), (american, NORP), (kea...  \n",
            "1  [(geena davis, PERSON), (samuel l jackson, PER...  \n",
            "2  [(hundreds, CARDINAL), (william randolph, PERS...  \n",
            "3                                [(second, ORDINAL)]  \n",
            "4                                 [(third, ORDINAL)]  \n",
            "                                          clean_text  \\\n",
            "0  comienza muy bien bonita intro y acumule para ...   \n",
            "1  película excelente si aún no lo observaste deb...   \n",
            "2  he visto cientos de películas silenciosas algu...   \n",
            "3  había estado buscando esta película durante ta...   \n",
            "4  bueno atractiva firefights cinematicales una g...   \n",
            "\n",
            "                                            entities  \n",
            "0                            [(keaton daniels, PER)]  \n",
            "1  [(geena davis, PER), (samuel l jackson, PER), ...  \n",
            "2  [(william randolph, PER), (georgia, LOC), (hol...  \n",
            "3                                     [(había, PER)]  \n",
            "4                                [(james bond, PER)]  \n"
          ]
        }
      ],
      "source": [
        "print(eng[[\"clean_text\", \"entities\"]].head())\n",
        "print(spa[[\"clean_text\", \"entities\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2FZjacr8yed",
        "outputId": "649ffdc1-ff20-4ac6-e9cc-caaf0735612e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NER datasets saved!\n"
          ]
        }
      ],
      "source": [
        "eng.to_csv(\"../data/processed/03_ner_english.csv\", index=False)\n",
        "spa.to_csv(\"../data/processed/03_ner_spanish.csv\", index=False)\n",
        "\n",
        "print(\"NER datasets saved!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNzYzUu/AIXdjbYvvrQ2Awi",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
