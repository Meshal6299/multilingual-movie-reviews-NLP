{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meshal6299/multilingual-movie-reviews-NLP/blob/main/notebooks/sampleGenerator_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrHGnAnNRgYG",
        "outputId": "278a27a5-a2b3-4e88-f5c2-38b2122b0f76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI6q7u877mcc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN5aZyk7Cveg"
      },
      "outputs": [],
      "source": [
        "def sample_imdb_data(input_file: str, output_file: str, max_samples: int = 1000, random_seed: int = 42):\n",
        "    try:\n",
        "        # 1. Load the dataset\n",
        "        df = pd.read_csv(input_file)\n",
        "        print(f\"Original dataset loaded with {len(df)} rows.\")\n",
        "\n",
        "        # 2. Separate the DataFrame into sentiment subsets\n",
        "        positive_df = df[df['sentiment'] == 'positive']\n",
        "        negative_df = df[df['sentiment'] == 'negative']\n",
        "\n",
        "        # 3. Randomly sample from each subset\n",
        "        # min() ensures we don't try to sample more rows than available\n",
        "        positive_sample = positive_df.sample(\n",
        "            n=min(max_samples, len(positive_df)),\n",
        "            random_state=random_seed\n",
        "        )\n",
        "        negative_sample = negative_df.sample(\n",
        "            n=min(max_samples, len(negative_df)),\n",
        "            random_state=random_seed\n",
        "        )\n",
        "\n",
        "        # 4. Combine and shuffle the samples\n",
        "        sampled_df = pd.concat([positive_sample, negative_sample])\n",
        "        # frac=1 shuffles the entire DataFrame\n",
        "        sampled_df = sampled_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "\n",
        "        # 5. Save the sampled DataFrame to a new CSV file\n",
        "        sampled_df.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"\\n--- Sampling Complete ---\")\n",
        "        print(f\"Positive reviews sampled: {len(positive_sample)}\")\n",
        "        print(f\"Negative reviews sampled: {len(negative_sample)}\")\n",
        "        print(f\"Total rows in new file: {len(sampled_df)}\")\n",
        "        print(f\"New dataset saved to: '{output_file}'\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{input_file}' was not found.\")\n",
        "    except KeyError:\n",
        "        print(\"Error: The CSV file must contain a column named 'sentiment'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic27eLMQ_qD4",
        "outputId": "29e1d9ea-0d83-42a4-d28a-6eec4eff58b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dataset loaded with 50000 rows.\n",
            "\n",
            "--- Sampling Complete ---\n",
            "Positive reviews sampled: 1000\n",
            "Negative reviews sampled: 1000\n",
            "Total rows in new file: 2000\n",
            "New dataset saved to: 'sampled_imdb_data.csv'\n"
          ]
        }
      ],
      "source": [
        "# --- Script Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # You MUST replace INPUT_FILE with your actual file name and path\n",
        "    INPUT_FILE = \"/content/drive/MyDrive/NLP Project/IMDB Dataset English.csv\"\n",
        "    OUTPUT_FILE = \"sampled_imdb_en.csv\"\n",
        "    MAX_SAMPLES_PER_CLASS = 1000\n",
        "\n",
        "    sample_imdb_data(INPUT_FILE, OUTPUT_FILE, MAX_SAMPLES_PER_CLASS)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM2FBF/fkZp3OKbyBfPawUZ",
      "include_colab_link": true,
      "mount_file_id": "1UiVIX5zpgA9SoTomIwMAfkM6PW-rUWQt",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
